{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f3fe049a",
   "metadata": {},
   "source": [
    "# DreamerV1 Code Explanation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "971eb721",
   "metadata": {},
   "source": [
    "## Core Algorithm in Paper"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "523506a6",
   "metadata": {},
   "source": [
    "### Dynamics Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f754824",
   "metadata": {},
   "source": [
    "### Behavior Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2591812",
   "metadata": {},
   "source": [
    "### Environment Interaction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f54b608e",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67f44bc1",
   "metadata": {},
   "source": [
    "### Representation Model\n",
    "\n",
    "Encoder + self.RSSM.recurrent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e333563",
   "metadata": {},
   "source": [
    "### Observation Model\n",
    "\n",
    "decoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5836a47a",
   "metadata": {},
   "source": [
    "### Reward Model\n",
    "\n",
    "rewardnet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "871863e7",
   "metadata": {},
   "source": [
    "### Transition Model\n",
    "\n",
    "self.rssm.transition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb727182",
   "metadata": {},
   "source": [
    "### Action Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f71d909",
   "metadata": {},
   "source": [
    "### Value Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bcfe123",
   "metadata": {},
   "source": [
    "## Latent Imagination"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd14608b",
   "metadata": {},
   "source": [
    "## Running xperiments"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
